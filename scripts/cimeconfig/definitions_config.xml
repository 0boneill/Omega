<?xml version="1.0"?>

<?xml-stylesheet type="text/xsl" href="definitions_variables.xsl" ?>

<definitions_variables> 

  <!-- ===================================================================== -->
  <!-- definitions case directories -->
  <!-- ===================================================================== -->

  <entry id="CASEROOT"> 
    <type>char</type>
    <value>UNSET</value>
    <group>case_def</group>
    <file>env_case.xml</file>
    <desc>full pathname of case</desc>
  </entry> 

  <entry id="LOGDIR"> 
    <type>char</type>
    <value>$CASEROOT/logs</value>
    <group>run_desc</group>
    <file>env_run.xml</file>
    <desc>Extra copies of the component log files will be saved here.</desc>
  </entry> 

  <entry id="CASETOOLS"> 
    <type>char</type>
    <value>$CASEROOT/Tools</value>
    <group>case_der</group>
    <file>env_case.xml</file>
    <desc>Case Tools directory location (derived variable, not in namelists</desc>
  </entry>

  <entry id="CASEBUILD"> 
    <type>char</type>
    <value>$CASEROOT/Buildconf</value>
    <group>case_der</group>
    <file>env_case.xml</file>
    <desc>Buildconf directory location (derived variable not in namelist)</desc>
  </entry>

  <entry id="SRCROOT"> 
    <type>char</type>
    <value>UNSET</value>
    <group>case_def</group>
    <file>env_case.xml</file>
    <desc>full pathname of source root directory</desc>
  </entry> 

  <entry id="CCSMROOT"> 
    <type>char</type>
    <value>UNSET</value>
    <group>case_def</group>
    <file>env_case.xml</file>
    <desc>full pathname of source root directory (currently equal to SRCROOT for backwards compatibility)</desc>
  </entry> 

  <entry id="CIMEROOT"> 
    <type>char</type>
    <value>UNSET</value>
    <group>case_def</group>
    <file>env_case.xml</file>
    <desc>full pathname of CIME source root directory</desc>
  </entry> 

  <entry id="SCRIPTSROOT"> 
    <type>char</type>
    <value>$CIMEROOT/scripts</value>
    <group>case_der</group>
    <file>env_case.xml</file>
    <desc>Scripts root directory location (setup automatically to $CIMEROOT/scripts- DO NOT EDIT)</desc>
  </entry>

  <entry id="UTILROOT"> 
    <type>char</type>
    <value>$CIMEROOT/scripts/Tools</value>
    <group>case_der</group>
    <file>env_case.xml</file>
    <desc>Scripts root utils directory location (setup automatically to $CIMEROOT/scripts/Tools - DO NOT EDIT)</desc>
  </entry>

  <!-- ===================================================================== -->
  <!-- definitions case -->
  <!-- ===================================================================== -->

  <entry id="CASE"> 
    <type>char*256</type>
    <value>UNSET</value>
    <group>case_def</group>
    <file>env_case.xml</file>
    <desc>case name</desc>
  </entry>

  <entry id="CASESTR"> 
    <type>char</type>
    <value>UNSET</value>
    <group>run_desc</group>
    <file>env_run.xml</file>
    <desc>case description</desc>
  </entry>

  <entry id='GRID'>
    <type>char</type>
    <value>UNSET</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>Model grid - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="COMPSET"> 
    <type>char</type>
    <value>UNSET</value>
    <group>case_last</group>
    <file>env_case.xml</file>
    <desc>Component set long name (for documentation only - DO NOT EDIT)</desc>
  </entry>

  <entry id="CIME_REPOTAG"> 
    <type>char</type>
    <value>UNSET</value>
    <group>run_desc</group>
    <file>env_run.xml</file>
    <desc>Version name of CIME repository tag</desc>
  </entry> 

  <entry id="CCSM_REPOTAG"> 
    <type>char</type>
    <value>UNSET</value>
    <group>run_desc</group>
    <file>env_run.xml</file>
    <desc>repository tag</desc>
  </entry> 

  <entry id="SUPPORTED_BY"> 
    <type>char</type>
    <value>UNSET</value>
    <group>case_def</group>
    <file>env_case.xml</file>
    <desc>current machine name support contact</desc>
  </entry>

  <entry id="USER"> 
    <type>char</type>
    <value>UNSET</value>
    <group>case_desc</group>
    <file>env_case.xml</file>
    <desc>case user name</desc>
  </entry> 

  <entry id="CCSMUSER"> 
    <type>char</type>
    <value>UNSET</value>
    <group>case_desc</group>
    <file>env_case.xml</file>
    <desc>case user name (this will be depracated in favor of USER moving forwards)</desc>
  </entry> 

  <!-- ===================================================================== -->
  <!-- definitions runtimes -->
  <!-- ===================================================================== -->

  <entry id="RUN_TYPE"> 
    <type>char</type>
    <valid_values>startup,hybrid,branch</valid_values>
    <value>startup</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      Determines the model run initialization type.  
      This setting is only important for the initial run of a production run when the 
      CONTINUE_RUN variable is set to FALSE.  After the initial run, the CONTINUE_RUN
      variable is set to TRUE, and the model restarts exactly using input
      files in a case, date, and bit-for-bit continuous fashion.
      Default: startup.
      -- In a startup run (the default), all components are initialized
      using baseline states.  These baseline states are set independently by
      each component and can include the use of restart files, initial
      files, external observed data files, or internal initialization (i.e.,
      a cold start). In a startup run, the coupler sends the start date to
      the components at initialization. In addition, the coupler does not
      need an input data file.  In a startup initialization, the ocean model
      does not start until the second ocean coupling (normally the second
      day).
      -- In a branch run, all components are initialized using a consistent
      set of restart files from a previous run (determined by the
      RUN_REFCASE and RUN_REFDATE variables in env_run.xml).  The case name
      is generally changed for a branch run, although it does not have to
      be. In a branch run, setting RUN_STARTDATE is ignored because the
      model components obtain the start date from their restart datasets.
      Therefore, the start date cannot be changed for a branch run. This is
      the same mechanism that is used for performing a restart run (where
      CONTINUE_RUN is set to TRUE in the env_run.xml) Branch runs are
      typically used when sensitivity or parameter studies are required, or
      when settings for history file output streams need to be modified
      while still maintaining bit-for-bit reproducibility. Under this
      scenario, the new case is able to produce an exact bit-for-bit restart
      in the same manner as a continuation run IF no source code or
      component namelist inputs are modified. All models use restart files
      to perform this type of run.  RUN_REFCASE and RUN_REFDATE are required
      for branch runs.
      To set up a branch run, locate the restart tar file or restart
      directory for RUN_REFCASE and RUN_REFDATE from a previous run, then
      place those files in the RUNDIR directory.
      --- In a hybrid run the model is initialized as a startup, BUT uses  
      initialization datasets FROM A PREVIOUS case.  This
      is somewhat analogous to a branch run with relaxed restart
      constraints.  A hybrid run allows users to bring together combinations
      of initial/restart files from a previous case (specified by
      RUN_REFCASE) at a given model output date (specified by
      RUN_REFDATE). Unlike a branch run, the starting date of a hybrid run
      (specified by RUN_STARTDATE) can be modified relative to the reference
      case. In a hybrid run, the model does not continue in a bit-for-bit
      fashion with respect to the reference case. The resulting climate,
      however, should be continuous provided that no model source code or
      namelists are changed in the hybrid run.  In a hybrid initialization,
      the ocean model does not start until the second ocean coupling
      (normally the second day), and the coupler does a cold start without
      a restart file.
    </desc>
  </entry>

  <entry id="RUN_REFDIR"> 
    <type>char*256</type>
    <value>ccsm4_init</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      Reference directory containing RUN_REFCASE data - used for hybrid or branch runs
    </desc>
  </entry>

  <entry id="RUN_REFCASE"> 
    <type>char*256</type>
    <value>case.std</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      Reference case for hybrid or branch runs
    </desc>
  </entry>

  <entry id="RUN_REFDATE"> 
    <type>char*10</type>
    <value>0001-01-01</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      Reference date for hybrid or branch runs (yyyy-mm-dd)
    </desc>
  </entry>

  <entry id="RUN_REFTOD"> 
    <type>char</type>
    <value>00000</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      Reference time of day (seconds) for hybrid or branch runs (sssss)
    </desc>
  </entry>

  <entry id="BRNCH_RETAIN_CASENAME"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      Allow same branch casename as reference casename. Only used for branch runs.
    </desc>
  </entry> 

  <entry id="GET_REFCASE"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      Flag for automatically prestaging the refcase restart dataset. 
      If TRUE, then the refcase data is prestaged into the executable directory
    </desc>
  </entry> 

  <entry id="RUN_STARTDATE"> 
    <type>char</type>
    <value>0001-01-01</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      Run start date (yyyy-mm-dd). Only used for startup or hybrid runs.
    </desc>
  </entry>

  <entry id="START_TOD"> 
    <type>integer</type>
    <value>0</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      Run start time-of-day
    </desc>
  </entry>

  <entry id="STOP_OPTION"> 
    <type>char</type>
    <valid_values>none,never,nsteps,nstep,nseconds,nsecond,nminutes,nminute,nhours,nhour,ndays,nday,nmonths,nmonth,nyears,nyear,date,ifdays0,end</valid_values>
    <value>ndays</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      Sets the run length along with STOP_N and STOP_DATE (must be nyear(s) for _GLC compsets for restarts to work properly).
    </desc>
  </entry>

  <entry id="STOP_N"> 
    <type>integer</type>
    <value>5</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      Provides a numerical count for $STOP_OPTION.
    </desc>
  </entry>

  <entry id="STOP_DATE"> 
    <type>integer</type>
    <value>-999</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      Alternative date yyyymmdd date option, sets the run length with STOP_OPTION and STOP_N
      negative value implies off
    </desc>
  </entry>

  <entry id="REST_OPTION"> 
    <type>char</type>
    <valid_values>none,never,nsteps,nstep,nseconds,nsecond,nminutes,nminute,nhours,nhour,ndays,nday,nmonths,nmonth,nyears,nyear,date,ifdays0,end</valid_values>
    <value>$STOP_OPTION</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      sets frequency of model restart writes (same options as STOP_OPTION) (must be nyear(s) for _GLC compsets)
      (must be nyear(s) for _GLC compsets)
    </desc>
  </entry>

  <entry id="REST_N"> 
    <type>char</type>
    <value>$STOP_N</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc> 
      sets model restart writes with REST_OPTION and REST_DATE
    </desc>
  </entry>

  <entry id="REST_DATE"> 
    <type>char</type>
    <value>$STOP_DATE</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      Alternative date in yyyymmdd format
      sets model restart write date with REST_OPTION and REST_N
    </desc>
  </entry>

  <entry id="CONTINUE_RUN"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>
      A setting of TRUE implies a continuation run    
      When you first begin a branch, hybrid or startup run, CONTINUE_RUN
      must be set to FALSE. When you successfully run and get a restart
      file, you will need to change CONTINUE_RUN to TRUE for the remainder
      of your run. This variable determines if the run is a restart run.   
      Set to FALSE when initializing a startup, branch or hybrid case.
      Set to TRUE when continuing a run.
    </desc>
  </entry>

  <entry id="RESUBMIT"> 
    <type>integer</type>
    <value>0</value>
    <group>run_begin_stop_restart</group>
    <file>env_run.xml</file>
    <desc>If RESUBMIT is greater than 0, then case will automatically resubmit
    Enables the model to automatically resubmit a new run.  To get
    multiple runs, set RESUBMIT greater than 0, then RESUBMIT will be
    decremented and the case will be resubmitted.  The case will stop automatically
    resubmitting when the RESUBMIT value reaches 0. 
    Long runs can easily outstrip supercomputer queue time limits. For
    this reason, a case is usually run as a series of jobs, each
    restarting where the previous finished.
    </desc>
  </entry>

  <!-- ===================================================================== -->
  <!-- definitions archive -->
  <!-- ===================================================================== -->

  <entry id="DOUT_S"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>TRUE</value>
    <group>run_data_archive</group>
    <file>env_run.xml</file>
    <desc>Logical to turn on short term archiving.
    If TRUE, short term archiving will be turned on.</desc>
  </entry>

  <entry id="DOUT_S_SAVE_INTERIM_RESTART_FILES"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_data_archive</group>
    <file>env_run.xml</file>
    <desc>Logical to archive all interim restart files, not just those at eor
    If TRUE, perform short term archiving on all interim restart files,
    not just those at the end of the run. By default, this value is FALSE.
    The restart files are saved under the specific component directory
    ($DOUT_S_ROOT/$CASE/$COMPONENT/rest rather than the top-level $DOUT_S_ROOT/$CASE/rest directory).
    Interim restart files are created using the REST_N and REST_OPTION variables.
    This is for expert users ONLY and requires expert knowledge. 
    We will not document this further in this guide.</desc>
  </entry> 

  <entry id="DOUT_S_SAVE_EVERY_NTH_RESTART_FILE_SET"> 
    <type>integer</type>
    <value>0</value>
    <group>run_data_archive</group>
    <file>env_run.xml</file>
    <desc>Save every Nth set of restart files and delete all others
      If value is greater than 0, then only save the nth restart set in the $DOUT_S_ROOT/$CASE/rest location. 
      Always preserve the most recent restart set regardless.</desc>
  </entry> 

  <entry id="DOUT_S_SAVE_ALL_ON_DISK"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>TRUE</value>
    <group>run_data_archive</group>
    <file>env_run.xml</file>
    <desc>logical to save contents of the short term archive on disk
      If TRUE, create hardlinks from the short term archive $DOUT_S_ROOT.locked/$CASE
      directory to the $DOUT_S_ROOT/$CASE directory.</desc>
  </entry> 

  <entry id="DOUT_S_GENERATE_TSERIES"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_data_archive</group>
    <file>env_run.xml</file>
    <desc>Logical to generate time-series files from the history time-slice files
    If TRUE, create the single variable time series files using the history time slice files.
    All the time invariant metadata is included in each variable time series file header. 
    Rules for how the tseries files are created are specified in the env_archive.xml file.</desc>
  </entry> 

  <entry id="DOUT_S_SAVE_HISTORY_FILES"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_data_archive</group>
    <file>env_run.xml</file>
    <desc>Logical to save history time slice files after the variable time series have been generated
    If TRUE, none of the history time slice files will be deleted from the $DOUT_S_ROOT/$CASE location after the
    variable time series files are successfully generated. *WARNING* setting this option to TRUE can
    more than double the disk space used by the output data for a given job.</desc>
  </entry> 

  <entry id="DOUT_L_MS"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_data_archive</group>
    <file>env_run.xml</file>
    <desc>If TRUE, perform long-term archiving on the output data.
      logical to turn on long term archiving (if DOUT_S is also TRUE)</desc>
  </entry>

  <entry id="DOUT_L_HPSS_ACCNT">
    <type>char</type>
    <value>00000000</value>
    <group>run_data_archive</group>
    <file>env_run.xml</file>
    <desc></desc>
  </entry>

  <entry id="DOUT_L_HTAR"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_data_archive</group>
    <file>env_run.xml</file>
    <desc>If true, DOUT_L_HTAR the long-term archiver will store history data in annual tar files. 
    Not currently implemented</desc>
  </entry> 

  <entry id="DOUT_L_SAVE_ALL_ON_DISK"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>TRUE</value>
    <group>run_data_archive</group>
    <file>env_run.xml</file>
    <desc>Save contents of short term archive on disk after the long term archiver has successfully completed
    If TRUE, this keeps the output data in DOUT_S_ROOT on disk after the long term (lt_archive.sh) archiver is run.</desc>
  </entry> 

  <!-- ===================================================================== -->
  <!-- definitions batch -->
  <!-- ===================================================================== -->

  <entry id="PERL5LIB">
    <type>char</type>
    <value></value>
    <group>build_derived</group>
    <file>env_build.xml</file>
    <desc>Perl 5 library directory</desc>
  </entry>

  <entry id="batch_system">
    <type>char</type>
    <value>UNSET</value>
    <group>config_batch</group>
    <file>env_case.xml</file>
    <desc>The batch system type for this particular machine</desc>
  </entry>

  <entry id="mpirun">
    <type>char</type>
    valid_values=""
    <value>UNSET</value>
    <group>config_batch</group>
    <file>env_case.xml</file>
    <desc>The mpi run command associated with the machine configured batch system</desc>
  </entry>

  <entry id="module_system">
    <type>char</type>
    <value>UNSET</value>
    <group>config_batch</group>
    <file>env_case.xml</file>
    <desc>The module system type defined for this machine</desc>
  </entry>

  <entry id="module_init_path">
    <type>char</type>
    <value>UNSET</value>
    <group>config_batch</group>
    <file>env_case.xml</file>
    <desc>The module initialization path for module system defined for this machine</desc>
  </entry>

  <entry id="module_cmd_path">
    <type>char</type>
    <value>UNSET</value>
    <group>config_batch</group>
    <file>env_case.xml</file>
    <desc>The module command path for module system defined for this machine</desc>
  </entry>

  <entry id="BATCHREDIRECT">
    <type>char</type>
    <value>UNSET</value>
    <group>run_mach</group>
    <file>env_case.xml</file>
    <desc>Batch redirect character</desc>
  </entry>

  <!-- ===================================================================== -->
  <!-- definitions build -->
  <!-- ===================================================================== -->

  <entry id="CESMSCRATCHROOT">
    <type>char</type>
    <valid_values></valid_values>
    <value>UNSET</value>
    <group>build_def</group>
    <file>env_build.xml</file>
    <desc>Scratch root directory for each machine. For now, primarily used for shared library builds
      The scratchroot root directory.  Base diretory for build and run directories.</desc>
  </entry>

  <entry id="EXEROOT"> 
    <type>char</type>
    <valid_values></valid_values>  
    <value>UNSET</value>
    <group>build_def</group>
    <file>env_build.xml</file>
    <desc>Case executable root directory. 
    (executable is $EXEROOT/cesm.exe, component libraries are in $EXEROOT/bld)
    This is where the model builds its executable and by default runs the executable.  
    Note that EXEROOT needs to have enough disk space for the experimental configuration
    requirements. As an example, a model run can produce more than a terabyte of
    data during a 100-year run, so you should set EXEROOT to scratch or
    tmp space and frequently back up the data to a long term archiving storage device
    For a supported machine, EXEROOT is set in $CIMEROOT/machines/config_machines.xml.
    For a userdefined machine, EXEROOT must explicitly be set it in env_build.xml.</desc>
  </entry> 

  <entry id="OS"> 
    <type>char</type>
    <valid_values></valid_values>
    <value>USERDEFINED_required_macros</value>
    <group>build_macros</group>
    <file>env_build.xml</file>
    <desc>Operating system - DO NOT EDIT UNLESS for userdefined machine - ignored once Macros has been created.</desc>
  </entry>

  <entry id="COMPILERS"> 
    <type>char</type>
    <valid_values></valid_values>  
    <value></value> 
    <group>build_macros</group>
    <file>env_build.xml</file>
    <desc>Set in $CIMEROOT/machines/config_machines.xml for each supported machine.
    Machine compiler (must match one the supported compilers) - ignored once Macros has been created.</desc>
  </entry> 

  <entry id="COMPILER"> 
    <type>char</type>
    <valid_values></valid_values>
    <value></value>
    <group>build_macros</group>
    <file>env_build.xml</file>
    <desc>Machine compiler (must match one the supported compilers)
    Set in $CIMEROOT/machines/config_machines.xml for each supported machine.
    Must be explicitly set in env_build.xml for userdefined machine.</desc>
  </entry> 

  <entry id="MPILIBS"> 
    <type>char</type>
    <valid_values></valid_values>  
    <value></value> 
    <group>build_macros</group>
    <file>env_build.xml</file>
    <desc>Supported mpi libraries for target machine - set in config_machines.xml - (DO NOT EDIT)
      Set in $CIMEROOT/machines/config_machines.xml for each supported machine.
      Must be explicitly set in env_build.xml for userdefined machine.</desc>
  </entry> 

  <entry id="SUPPORTED_BY"> 
    <type>char</type>
    <valid_values></valid_values>
    <value></value>
    <group>build_def</group>
    <file>env_build.xml</file>
    <desc>email address of person (or group) that supports the build and port for this machine (do not edit)></desc>
  </entry> 

  <entry id="MPILIB"> 
    <type>char</type>
    <valid_values></valid_values>  
    <value>USERDEFINED_required_macros</value>
    <group>build_macros</group>
    <file>env_build.xml</file>
    <desc>mpi library (must match one of the supported libraries) - 
    ignored once Macros has been created
    Set in $CIMEROOT/machines/config_machines.xml for each supported machine.
    Must be explicitly set in env_build.xml for userdefined machine.</desc>
  </entry> 

  <entry id="CALENDAR"> 
    <type>char</type>
    <valid_values>NO_LEAP,GREGORIAN</valid_values>
    <value>NO_LEAP</value>
    <group>build_def</group>
    <file>env_build.xml</file>
    <desc>calendar type></desc>
  </entry>

  <entry id="COMP_INTERFACE"> 
    <type>char</type>
    <valid_values>MCT,ESMF</valid_values>
    <value>MCT</value>
    <group>build_def</group>
    <file>env_build.xml</file>
    <desc>use MCT or ESMF component interfaces</desc>
  </entry>

  <entry id="USE_ESMF_LIB"> 
    <type>char</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>build_def</group>
    <file>env_build.xml</file>
    <desc>TRUE implies using the ESMF library specified by ESMF_LIBDIR or ESMFMKFILE</desc>
  </entry>

  <entry id="DEBUG"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values> 
    <value>FALSE</value>
    <group>build_def</group>
    <file>env_build.xml</file>
    <desc>TRUE implies turning on run and compile time debugging
      Flag to turn on debugging for run time and compile time. 
      If TRUE, compile-time debugging flags are activated that you can use to verify 
      software robustness, such as bounds checking.
      Important:: On IBM machines, floating point trapping is not activated for production 
      runs (i.e., non-DEBUG), due to performance penalties associated with turning on these flags.</desc>
  </entry> 

  <entry id="BUILD_THREADED"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>build_def</group>
    <file>env_build.xml</file>
    <desc>TRUE implies always build model for openmp capability
      If FALSE, component libraries are built with OpenMP capability only if 
      the NTHREADS_ setting for that component is greater than 1 in env_mach_pes.xml.
      If TRUE, the component libraries are always built with OpenMP capability.</desc>
  </entry> 

  <entry id="USE_TRILINOS">
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>build_def</group>
    <file>env_build.xml</file>
    <desc>TRUE implies linking to the trilinos library - set automatically by XXX_USE_TRILINOS options (do not edit)
      Flag to turn on linking to the trilinos library. Currently this is
      used by CISM. Note that trilinos is a C++ library, so setting this
      variable to TRUE will involve the inclusion of C++ code in the model
      executable. This is currently only supported for certain machines.</desc>
  </entry>

  <entry id="GMAKE"> 
    <type>char</type>
    <valid_values></valid_values>
    <value>gmake</value>
    <group>build_def</group>
    <file>env_build.xml</file>
    <desc>GNU make command</desc>
  </entry>

  <entry id="GMAKE_J"> 
    <type>integer</type>
    <valid_values></valid_values> 
    <value>1</value>
    <group>build_def</group>
    <file>env_build.xml</file>
    <desc>Number of processors for gmake</desc>
  </entry>

  <entry id="BUILD_COMPLETE"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>build_status</group>
    <file>env_build.xml</file>
    <desc>Status output: if TRUE, models have been built successfully. (DO NOT EDIT)></desc>
  </entry> 

  <entry id="SMP_BUILD"> 
    <type>char</type>
    <valid_values></valid_values>  
    <value>0</value>
    <group>build_status</group>
    <file>env_build.xml</file>
    <desc>Status: smp status of previous build, coded string. (DO NOT EDIT)></desc>
  </entry> 

  <entry id="SMP_VALUE"> 
    <type>char</type>
    <valid_values></valid_values>
    <value>0</value>
    <group>build_status</group>
    <file>env_build.xml</file>
    <desc>Status: smp status of current case, coded string (DO NOT EDIT)></desc>
  </entry> 

  <entry id="NINST_BUILD"> 
    <type>char</type>
    <valid_values></valid_values>  
    <value>0</value>
    <group>build_status</group>
    <file>env_build.xml</file>
    <desc>Status: ninst status of previous build, coded string. (DO NOT EDIT)></desc>
  </entry> 

  <entry id="NINST_VALUE"> 
    <type>char</type>
    <valid_values></valid_values>
    <value>0</value>
    <group>build_status</group>
    <file>env_build.xml</file>
    <desc>Status: ninst status of current case, coded string (DO NOT EDIT)></desc>
  </entry> 

  <entry id="BUILD_STATUS"> 
    <type>integer</type>
    <valid_values></valid_values>  
    <value>0</value>
    <group>build_status</group>
    <file>env_build.xml</file>
    <desc>Status: of prior build. (DO NOT EDIT)></desc>
  </entry> 

  <entry id="OBJROOT"> 
    <type>char</type>
    <valid_values></valid_values>
    <value>$EXEROOT</value>
    <group>build_derived</group>
    <file>env_build.xml</file>
    <desc>case build directory (set automatically to $EXEROOT, - DO NOT EDIT)</desc>
  </entry>

  <entry id="LIBROOT"> 
    <type>char</type>
    <valid_values></valid_values> 
    <value>$EXEROOT/lib</value>
    <group>build_derived</group>
    <file>env_build.xml</file>
    <desc>case lib directory (set automatically to $EXEROOT/lib - DO NOT EDIT)</desc>
  </entry>

  <entry id="INCROOT"> 
    <type>char</type>
    <valid_values></valid_values>
    <value>$EXEROOT/lib/include</value>
    <group>build_derived</group>
    <file>env_build.xml</file>
    <desc>case lib include directory (set automatically to $EXEROOT/lib/include - DO NOT EDIT)</desc>
  </entry>

  <entry id="SHAREDLIBROOT">
    <type>char</type>
    <valid_values></valid_values>
    <value>$EXEROOT</value>
    <group>build_derived</group>
    <file>env_build.xml</file>
    <desc>Shared library root, (set automatically to $EXEROOT - DO NOT EDIT)</desc>
  </entry>

  <entry id="SHAREDLIBROOTDIR">
    <type>char</type>
    <valid_values></valid_values>
    <value>$EXEROOT</value>
    <group>build_derived</group>
    <file>env_build.xml</file>
    <desc>Shared library root directory, neeed for cleaning shared builds (set automatically to $EXEROOT - DO NOT EDIT)</desc>
  </entry>

  <!-- ===================================================================== -->
  <!-- definitions performance -->
  <!-- ===================================================================== -->

  <entry id="CHECK_TIMING"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>TRUE</value>
    <group>run_flags</group>
    <file>env_run.xml</file>
    <desc>logical to diagnose model timing at the end of the run</desc>
  </entry>

  <entry id="SAVE_TIMING"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_flags</group>
    <file>env_run.xml</file>
    <desc>logical to save timing files in rundir</desc>
  </entry>

  <entry id="TIMER_LEVEL"> 
    <type>integer</type>
    <value>12</value>
    <group>run_flags</group>
    <file>env_run.xml</file>
    <desc>timer output depth</desc>
  </entry>

  <entry id="PROFILE_PAPI_ENABLE">
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_cesm</group>
    <file>env_run.xml</file>
    <desc>Enables the papi hardware counters in gptl
    The papi library must be included in the build step for 
    this to work.</desc>
  </entry>

  <entry id="COMP_RUN_BARRIERS"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_flags</group>
    <file>env_run.xml</file>
    <desc>Turns on component barriers for component timing</desc>
  </entry>

  <entry id="CCSM_PCOST">
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_last</group>
    <file>env_mach_pes.xml</file>
    <desc>cost relative to 64 pes (DO NOT EDIT)</desc>
  </entry>

  <entry id="CCSM_TCOST"> 
    <type>integer</type>
    <value>0</value> 
    <group>mach_pes_last</group>
    <file>env_mach_pes.xml</file>
    <desc>relative cost of test where ERS is 1 (DO NOT EDIT)</desc>
  </entry>

  <entry id="CCSM_ESTCOST"> 
    <type>integer</type>
    <value>0</value> 
    <group>mach_pes_last</group>
    <file>env_mach_pes.xml</file>
    <desc>relative total cost of case (DO NOT EDIT)</desc>
  </entry>

  <entry id="COST_PES"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_last</group>
    <file>env_mach_pes.xml</file>
    <desc>pes or cores used relative to PES_PER_NODE for accounting (0 means TOTALPES is valid)</desc>
  </entry>

  <!-- ===================================================================== -->
  <!-- definitions grid -->
  <!-- ===================================================================== -->

  <entry id="ATM_GRID">
    <type>char</type>
    <value>UNSET</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>atmosphere grid - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="ATM_NX">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of atmosphere cells in i direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="ATM_NY">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of atmosphere cells in j direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="LND_GRID">
    <type>char</type>
    <value>UNSET</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>land grid - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="LND_NX">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of land cells in i direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="LND_NY">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of land cells in j direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="OCN_GRID">
    <type>char</type>
    <value>UNSET</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>ocn grid - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="OCN_NX">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of ocn cells in i direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="OCN_NY">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of ocn cells in j direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="ICE_GRID">
    <type>char</type>
    <value>UNSET</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>ice grid (must equal ocn grid) - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="ICE_NX">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of ice cells in i direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="ICE_NY">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of ice cells in j direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="ROF_GRID">
    <type>char</type>
    <value>UNSET</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>river runoff (rof) grid</desc>
  </entry>

  <entry id="ROF_NX">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of rof cells in i direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="ROF_NY">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of rof cells in j direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="GLC_GRID">
    <type>char</type>
    <value>UNSET</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>(glc) grid for the coupler</desc>
  </entry>

  <entry id="GLC_NX">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of glc cells in i direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="GLC_NY">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of glc cells in j direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="CISM_GRID">
    <type>char</type>
    <valid_values>gland20,gland10,gland5,gland5UM,gland4,null</valid_values>
    <value>gland5UM</value>
    <group>run_component_cism</group>
    <file>env_run.xml</file>
    <desc>
      The glacier model (glc) grid for coupling is assumed to be identical to the land grid. 
      CISM_GRID determines the specific local internal grid that CISM will use for 
      internal calculations. 
      The default is gland5UM (5km grid).
    </desc>
  </entry> 

  <entry id="WAV_GRID">
    <type>char</type>
    <value>UNSET</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>wave model (wav) grid</desc>
  </entry>

  <entry id="WAV_NX">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of wav cells in i direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="WAV_NY">
    <type>integer</type>
    <value>0</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>number of wav cells in j direction - DO NOT EDIT (for experts only)</desc>
  </entry>

  <entry id="MASK_GRID">
    <type>char</type>
    <value>UNSET</value>
    <group>build_grid</group>
    <file>env_build.xml</file>
    <desc>grid mask - DO NOT EDIT (for experts only)</desc>
  </entry>

  <!-- ======================================================================= -->
  <!--  DOMAIN FILES (drv)                                          -->
  <!-- ======================================================================= -->

  <entry id="ATM_DOMAIN_FILE">
    <type>char</type>
    <value>UNSET</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>atm domain file</desc>
  </entry>

  <entry id="ATM_DOMAIN_PATH">
    <type>char</type>
    <value>$DIN_LOC_ROOT/share/domains</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>path of atm domain file</desc>
  </entry>

  <entry id="LND_DOMAIN_FILE">
    <type>char</type>
    <value>UNSET</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>lnd domain file</desc>
  </entry>

  <entry id="LND_DOMAIN_PATH">
    <type>char</type>
    <value>$DIN_LOC_ROOT/share/domains</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>path of lnd domain file</desc>
  </entry>

  <entry id="ROF_DOMAIN_FILE">
    <type>char</type>
    <value>UNSET</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>rof domain file</desc>
  </entry>

  <entry id="ROF_DOMAIN_PATH">
    <type>char</type>
    <value>$DIN_LOC_ROOT/share/domains</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>path of rof domain file</desc>
  </entry>

  <entry id="WAV_DOMAIN_FILE">
    <type>char</type>
    <value>UNSET</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>wav domain file</desc>
  </entry>

  <entry id="WAV_DOMAIN_PATH">
    <type>char</type>
    <value>$DIN_LOC_ROOT/share/domains</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>path of wav domain file</desc>
  </entry>

  <entry id="ICE_DOMAIN_FILE">
    <type>char</type>
    <value>UNSET</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>ice domain file</desc>
  </entry>

  <entry id="ICE_DOMAIN_PATH">
    <type>char</type>
    <value>$DIN_LOC_ROOT/share/domains</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>path of ice domain file</desc>
  </entry>

  <entry id="OCN_DOMAIN_FILE">
    <type>char</type>
    <value>UNSET</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>ocn domain file</desc>
  </entry>

  <entry id="OCN_DOMAIN_PATH">
    <type>char</type>
    <value>$DIN_LOC_ROOT/share/domains</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>path of ocn domain file</desc>
  </entry>

  <entry id="GLC_DOMAIN_FILE">
    <type>char</type>
    <value>UNSET</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>glc domain file</desc>
  </entry>

  <entry id="GLC_DOMAIN_PATH">
    <type>char</type>
    <value>$DIN_LOC_ROOT/share/domains</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>path of glc domain file</desc>
  </entry>

  <!--- map files -->
  <!--- comment out map type for now, tcraig 3/25/13 -->

  <entry id="ATM2OCN_FMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>atm2ocn flux mapping file</desc>
  </entry>

  <!-- 
       <entry id="ATM2OCN_FMAPTYPE">
       <type>char</type>
       <valid_values>X,Y</valid_values>
       <value>X</value>
       <group>run_domain</group>
       <file>env_run.xml</file>
       <desc>atm2ocn flux mapping file decomp type</desc>
       </entry>
  -->

  <entry id="ATM2OCN_SMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>atm2ocn state mapping file</desc>
  </entry>

  <!-- 
       <entry id="ATM2OCN_SMAPTYPE">
       <type>char</type>
       <valid_values>X,Y</valid_values>
       <value>X</value>
       <group>run_domain</group>
       <file>env_run.xml</file>
       <desc>atm2ocn state mapping file decomp type</desc>
       </entry>
  -->

  <entry id="ATM2OCN_VMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>atm2ocn vector mapping file</desc>
  </entry>

  <!--- 
      <entry id="ATM2OCN_VMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>X</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>atm2ocn vector mapping file decomp type</desc>
      </entry>
  -->

  <entry id="OCN2ATM_FMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>ocn2atm flux mapping file</desc>
  </entry>

  <!--- 
      <entry id="OCN2ATM_FMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>Y</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>ocn2atm flux mapping file decomp type</desc>
      </entry>
  -->

  <entry id="OCN2ATM_SMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>ocn2atm state mapping file</desc>
  </entry>

  <!--- 
      <entry id="OCN2ATM_SMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>Y</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>ocn2atm state mapping file decomp type</desc>
      </entry>
  -->

  <entry id="ATM2LND_FMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>atm2lnd flux mapping file</desc>
  </entry>

  <!--- 
      <entry id="ATM2LND_FMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>X</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>atm2lnd flux mapping file decomp type</desc>
      </entry>
  -->

  <entry id="ATM2LND_SMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>atm2lnd state mapping file</desc>
  </entry>

  <!--- 
      <entry id="ATM2LND_SMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>X</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>atm2lnd state mapping file decomp type</desc>
      </entry>
  -->

  <entry id="LND2ATM_FMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>lnd2atm flux mapping file</desc>
  </entry>

  <!--- 
      <entry id="LND2ATM_FMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>Y</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>lnd2atm flux mapping file decomp type</desc>
      </entry>
  -->

  <entry id="LND2ATM_SMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>lnd2atm state mapping file</desc>
  </entry>

  <!--- 
      <entry id="LND2ATM_SMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>Y</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>lnd2atm state mapping file decomp type</desc>
      </entry>
  -->

  <entry id="ROF2LND_FMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>rof2lnd flux mapping file</desc>
  </entry>

  <!--- 
      <entry id="ROF2LND_FMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>Y</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>rof2lnd flux mapping file decomp type</desc>
      </entry>
  -->

  <entry id="LND2ROF_FMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>lnd2rof flux mapping file</desc>
  </entry>

  <!--- 
      <entry id="LND2ROF_FMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>X</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>lnd2rof flux mapping file decomp type</desc>
      </entry>
  -->

  <entry id="ROF2OCN_FMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>rof2ocn flux mapping file</desc>
  </entry>

  <!--- 
      <entry id="ROF2OCN_FMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>Y</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>rof2ocn flux mapping file decomp type</desc>
      </entry>
  -->

  <entry id="ROF2OCN_RMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>rof2ocn runoff mapping file</desc>
  </entry>

  <!--- 
      <entry id="ROF2OCN_RMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>Y</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>rof2ocn runoff mapping file decomp type</desc>
      </entry>
  -->

  <entry id="GLC2OCN_RMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>glc2ocn runoff mapping file</desc>
  </entry>

  <!--- 
      <entry id="GLC2OCN_RMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>Y</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>glc2ocn runoff mapping file decomp type</desc>
      </entry>
  -->

  <entry id="GLC2ICE_RMAPNAME"> 
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>glc2ice runoff mapping file</desc>
  </entry>

  <!--- 
      <variable name>GLC2ICE_RMAPTYPE"></<variable name>
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>Y</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>glc2ice runoff mapping file decomp type</desc>
      </entry>
  -->

  <entry id="ATM2WAV_SMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>atm2wav state mapping file</desc>
  </entry>

  <!--- 
      <entry id="ATM2WAV_SMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>Y</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>atm2wav state mapping file decomp type</desc>
      </entry>
  -->

  <entry id="OCN2WAV_SMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>ocn2wav state mapping file</desc>
  </entry>

  <!--- 
      <entry id="OCN2WAV_SMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>Y</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>ocn2wav state mapping file decomp type</desc>
      </entry>
  -->

  <entry id="ICE2WAV_SMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>ice2wav state mapping file</desc>
  </entry>

  <!--- 
      <entry id="ICE2WAV_SMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>Y</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>ice2wav state mapping file decomp type</desc>
      </entry>
  -->

  <entry id="WAV2OCN_SMAPNAME">
    <type>char</type>
    <value>idmap</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>wav2ocn state mapping file</desc>
  </entry>

  <!--- 
      <entry id="WAV2OCN_SMAPTYPE">
      <type>char</type>
      <valid_values>X,Y</valid_values>
      <value>X</value>
      <group>run_domain</group>
      <file>env_run.xml</file>
      <desc>wav2ocn state mapping file decomp type</desc>
      </entry>
  -->

  <entry id="VECT_MAP">
    <type>char</type>
    <valid_values>none,npfix,cart3d,cart3d_diag,cart3d_uvw,cart3d_uvw_diag</valid_values>
    <value>cart3d</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>vector mapping option</desc>
  </entry>

  <entry id="EPS_FRAC">
    <type>char</type>
    <value>1.0e-02</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>Error tolerance for differences in fractions in domain checking</desc>
  </entry>

  <entry id="EPS_AAREA">
    <type>real</type>
    <value>1.0e-07</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>Error tolerance for differences in atm/land areas in domain checking</desc>
  </entry>

  <entry id="EPS_AMASK">
    <type>real</type>
    <value>1.0e-13</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>Error tolerance for differences in atm/land masks in domain checking</desc>
  </entry>

  <entry id="EPS_AGRID">
    <type>real</type>
    <value>1.0e-12</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>Error tolerance for differences in atm/land lat/lon in domain checking</desc>
  </entry>

  <entry id="EPS_OAREA">
    <type>real</type>
    <value>1.0e-01</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>Error tolerance for differences in ocean/ice lon/lat in domain checking</desc>
  </entry>

  <entry id="EPS_OMASK">
    <type>real</type>
    <value>1.0e-06</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>Error tolerance for differences in ocean/ice lon/lat in domain checking</desc>
  </entry>

  <entry id="EPS_OGRID">   
    <type>real</type>
    <value>1.0e-02</value>
    <group>run_domain</group>
    <file>env_run.xml</file>
    <desc>Error tolerance for differences in ocean/ice lon/lat in domain checking</desc>
  </entry>

  <!-- ===================================================================== -->
  <!-- definitions machine -->
  <!-- ===================================================================== -->

  <entry id="MACH"> 
    <type>char</type>
    <value>UNSET</value>
    <group>case_def</group>
    <file>env_case.xml</file>
    <desc>Machine name</desc>
  </entry>

  <entry id="MACHINES_FILE">
    <type>char</type>
    <value></value>
    <group>case_def</group>
    <file>env_case.xml</file>
    <desc>full pathname of file specifying supported machines location</desc>
  </entry>

  <entry id="MACHDIR">
    <type>char</type>
    <value></value>
    <group>case_def</group>
    <file>env_case.xml</file>
    <desc>Machines directory location</desc>
  </entry>

  <entry id="RUNDIR"> 
    <type>char</type>
    <value>UNSET</value>
    <group>run_desc</group>
    <file>env_case.xml</file>
    <desc>
      The directory where the executable will be run. 
      By default this is set to EXEROOT/../run. 
      RUNDIR allows you to keep the run directory separate from the build directory
    </desc>
  </entry>

  <entry id="DIN_LOC_ROOT"> 
    <type>char</type>
    <value>UNSET</value>
    <group>run_din</group>
    <file>env_run.xml</file>
    <desc>
      The root directory of all CIME and component input data for the selected machine.
      This is usually a shared disk area.
      Default values for the target machine are in the
      $CIMEROOT/machines/config_machines.xml
    </desc>
  </entry> 

  <entry id="DIN_LOC_ROOT_CLMFORC"> 
    <type>char</type>
    <value>UNSET</value>
    <group>run_din</group>
    <file>env_run.xml</file>
    <desc>CLM-specific root directory for CLM type input forcing data
    This directory will only be used for I (CLM/DATM) compsets and only
    for datm forcing data that is NOT checked into the svn repository
    (datasets other than the Qian or single-point forcing).
    This is usually a shared disk area.
    Default values for the target machine are in the
    $CIMEROOT/machines/config_machines.xml</desc>
  </entry> 

  <entry id="DOUT_S_ROOT"> 
    <type>char</type> 
    <value>UNSET</value>
    <group>run_dout</group>
    <file>env_run.xml</file>
    <desc>Root directory for short term archiving. This directory must be visible to compute nodes.</desc> 
  </entry> 

  <entry id="DOUT_L_MSROOT"> 
    <type>char</type>
    <value>UNSET</value>
    <group>run_dout</group>
    <file>env_run.xml</file>
    <desc>Root directory on long term archiving store system for long-term data archives.</desc>
  </entry> 

  <entry id="PROJECT"> 
    <type>char</type>
    <value>PROJECT_UNSET</value>
    <group>case_desc</group>
    <file>env_case.xml</file>
    <desc>project for project-sensitive build and run paths, and job scripts</desc>
  </entry> 

  <entry id="PROJECT_REQUIRED">
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>case_desc</group>
    <file>env_case.xml</file>
    <desc>whether the PROJECT value is required on this machine</desc>
  </entry>

  <entry id="BATCHQUERY"> 
    <type>char</type>
    <value>UNSET</value>
    <group>run_mach</group>
    <file>env_run.xml</file>
    <desc>command used to query batch system</desc>
  </entry>

  <entry id="BATCHSUBMIT"> 
    <type>char</type>
    <value>UNSET</value>
    <group>run_mach</group>
    <file>env_run.xml</file>
    <desc>command used to submit to batch system</desc>
  </entry>

  <entry id="MPI_RUN_COMMAND"> 
    <type>char</type>
    <value>UNSET</value>
    <group>run_mpi</group>
    <file>env_run.xml</file>
    <desc>mpi run command</desc>
  </entry>

  <!-- ===================================================================== -->
  <!-- definitions pelayout -->
  <!-- ===================================================================== -->

  <entry id="NTASKS_ATM"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_atm</group>
    <file>env_mach_pes.xml</file>
    <desc>number of atmosphere tasks</desc>
  </entry>

  <entry id="NTHRDS_ATM"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_atm</group>
    <file>env_mach_pes.xml</file>
    <desc>number of atmosphere threads</desc>
  </entry>

  <entry id="ROOTPE_ATM"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_atm</group>
    <file>env_mach_pes.xml</file>
    <desc>root atm mpi task</desc>
  </entry>

  <entry id="NINST_ATM">
    <type>integer</type>
    <value>1</value>
    <group>mach_pes_atm</group>
    <file>env_mach_pes.xml</file>
    <desc>Number of atmosphere instances</desc>
  </entry>

  <entry id="NINST_ATM_LAYOUT">
    <type>char</type>
    <valid_values>sequential,concurrent</valid_values>
    <value>concurrent</value>
    <group>mach_pes_atm</group>
    <file>env_mach_pes.xml</file>
    <desc>Layout of atmosphere instances</desc>
  </entry>

  <entry id="NTASKS_LND"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_lnd</group>
    <file>env_mach_pes.xml</file>
    <desc>number of land mpi tasks</desc>
  </entry>

  <entry id="NTHRDS_LND"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_lnd</group>
    <file>env_mach_pes.xml</file>
    <desc>number of land mpi threads</desc>
  </entry>

  <entry id="ROOTPE_LND"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_lnd</group>
    <file>env_mach_pes.xml</file>
    <desc>root lnd mpi task</desc>
  </entry>

  <entry id="NINST_LND">
    <type>integer</type>
    <value>1</value>
    <group>mach_pes_lnd</group>
    <file>env_mach_pes.xml</file>
    <desc>Number of land instances</desc>
  </entry>

  <entry id="NINST_LND_LAYOUT">
    <type>integer</type>
    <valid_values>sequential,concurrent</valid_values>
    <value>concurrent</value>
    <group>mach_pes_lnd</group>
    <file>env_mach_pes.xml</file>
    <desc>Layout of land instances</desc>
  </entry>

  <entry id="NTASKS_ICE"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_ice</group>
    <file>env_mach_pes.xml</file>
    <desc>number of ice mpi tasks</desc>
  </entry>

  <entry id="NTHRDS_ICE"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_ice</group>
    <file>env_mach_pes.xml</file>
    <desc>number of ice mpi threads</desc>
  </entry>

  <entry id="ROOTPE_ICE"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_ice</group>
    <file>env_mach_pes.xml</file>
    <desc>root ice mpi task</desc>
  </entry>

  <entry id="NINST_ICE">
    <type>integer</type>
    <value>1</value>
    <group>mach_pes_ice</group>
    <file>env_mach_pes.xml</file>
    <desc>Number of sea ice instances</desc>
  </entry>

  <entry id="NINST_ICE_LAYOUT">
    <type>integer</type>
    <valid_values>equential,concurrent</valid_values>
    <value>concurrent</value>
    <group>mach_pes_ice</group>
    <file>env_mach_pes.xml</file>
    <desc>Layout of sea ice instances</desc>
  </entry>

  <entry id="NTASKS_OCN"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_ocn</group>
    <file>env_mach_pes.xml</file>
    <desc>number of ocean mpi tasks</desc>
  </entry>

  <entry id="NTHRDS_OCN"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_ocn</group>
    <file>env_mach_pes.xml</file>
    <desc>number of ocean mpi threads</desc>
  </entry>

  <entry id="ROOTPE_OCN"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_ocn</group>
    <file>env_mach_pes.xml</file>
    <desc>root ocn mpi task</desc>
  </entry>

  <entry id="NINST_OCN">
    <type>integer</type>
    <value>1</value>
    <group>mach_pes_ocn</group>
    <file>env_mach_pes.xml</file>
    <desc>Number of ocean instances</desc>
  </entry>

  <entry id="NINST_OCN_LAYOUT">
    <type>char</type>
    <valid_values>sequential,concurrent</valid_values>
    <value>concurrent</value>
    <group>mach_pes_ocn</group>
    <file>env_mach_pes.xml</file>
    <desc>Layout of ocean instances</desc>
  </entry>

  <entry id="NTASKS_CPL"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_cpl</group>
    <file>env_mach_pes.xml</file>
    <desc>number of coupler mpi tasks</desc>
  </entry>

  <entry id="NTHRDS_CPL"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_cpl</group>
    <file>env_mach_pes.xml</file>
    <desc>number of coupler mpi threads</desc>
  </entry>

  <entry id="ROOTPE_CPL"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_cpl</group>
    <file>env_mach_pes.xml</file>
    <desc>root cpl mpi task</desc>
  </entry>

  <entry id="NTASKS_GLC"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_glc</group>
    <file>env_mach_pes.xml</file>
    <desc>number of glc mpi tasks</desc>
  </entry>

  <entry id="NTHRDS_GLC"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_glc</group>
    <file>env_mach_pes.xml</file>
    <desc>number of glc mpi threads</desc>
  </entry>

  <entry id="ROOTPE_GLC"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_glc</group>
    <file>env_mach_pes.xml</file>
    <desc>root glc mpi task</desc>
  </entry>

  <entry id="NINST_GLC">
    <type>integer</type>
    <value>1</value>
    <group>mach_pes_glc</group>
    <file>env_mach_pes.xml</file>
    <desc>Number of glacier instances</desc>
  </entry>

  <entry id="NINST_GLC_LAYOUT">
    <type>char</type>
    <valid_values>sequential,concurrent</valid_values>
    <value>concurrent</value>
    <group>mach_pes_glc</group>
    <file>env_mach_pes.xml</file>
    <desc>Layout of glacier instances</desc>
  </entry>

  <entry id="NTASKS_ROF"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_rof</group>
    <file>env_mach_pes.xml</file>
    <desc>number of river runoff tasks</desc>
  </entry>

  <entry id="NTHRDS_ROF"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_rof</group>
    <file>env_mach_pes.xml</file>
    <desc>number of river runoff threads</desc>
  </entry>

  <entry id="ROOTPE_ROF"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_rof</group>
    <file>env_mach_pes.xml</file>
    <desc>root rof mpi task</desc>
  </entry>

  <entry id="NINST_ROF">
    <type>integer</type>
    <value>1</value>
    <group>mach_pes_rof</group>
    <file>env_mach_pes.xml</file>
    <desc>Number of river runoff instances</desc>
  </entry>

  <entry id="NINST_ROF_LAYOUT">
    <type>char</type>
    <value>concurrent</value>
    <group>mach_pes_rof</group>
    <file>env_mach_pes.xml</file>
    <desc>Layout of river runoff instances</desc>
  </entry>

  <entry id="NTASKS_WAV">
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_wav</group>
    <file>env_mach_pes.xml</file>
    <desc>number of wav mpi tasks</desc>
  </entry>

  <entry id="NTHRDS_WAV">
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_wav</group>
    <file>env_mach_pes.xml</file>
    <desc>number of wav mpi threads</desc>
  </entry>

  <entry id="ROOTPE_WAV">
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_wav</group>
    <file>env_mach_pes.xml</file>
    <desc>root wav mpi task</desc>
  </entry>

  <entry id="NINST_WAV">
    <type>integer</type>
    <value>1</value>
    <group>mach_pes_wav</group>
    <file>env_mach_pes.xml</file>
    <desc>Number of wave instances</desc>
  </entry>

  <entry id="NINST_WAV_LAYOUT">
    <type>char</type>
    <valid_values>sequential,concurrent</valid_values>
    <value>concurrent</value>
    <group>mach_pes_wav</group>
    <file>env_mach_pes.xml</file>
    <desc>Layout of wave instances</desc>
  </entry>

  <entry id="PSTRID_ATM">
    <type>integer</type>
    <value>1</value>
    <group>mach_pes_stride</group>
    <file>env_mach_pes.xml</file>
    <desc>stride of mpi tasks for atm comp - currently should always be set to 1</desc>
  </entry>

  <entry id="PSTRID_LND">
    <type>integer</type>
    <valid_values>1</valid_values>
    <value>1</value>
    <group>mach_pes_stride</group>
    <file>env_mach_pes.xml</file>
    <desc>stride of mpi tasks for lnd comp - currently should always be set to 1</desc>
  </entry>

  <entry id="PSTRID_ICE">
    <type>integer</type>
    <value>1</value>
    <group>mach_pes_stride</group>
    <file>env_mach_pes.xml</file>
    <desc>stride of mpi tasks for ice comp - currently should always be set to 1</desc>
  </entry>

  <entry id="PSTRID_OCN">
    <type>integer</type>
    <valid_values>1</valid_values>
    <value>1</value>
    <group>mach_pes_stride</group>
    <file>env_mach_pes.xml</file>
    <desc>stride of mpi tasks for ocn comp - currently should always be set to 1</desc>
  </entry>

  <entry id="PSTRID_CPL">
    <type>integer</type>
    <value>1</value>
    <group>mach_pes_stride</group>
    <file>env_mach_pes.xml</file>
    <desc>stride of mpi tasks for cpl comp - currently should always be set to 1</desc>
  </entry>

  <entry id="PSTRID_GLC">
    <type>integer</type>
    <valid_values>1</valid_values>
    <value>1</value>
    <group>mach_pes_stride</group>
    <file>env_mach_pes.xml</file>
    <desc>stride of mpi tasks for glc comp - currently should always be set to 1</desc>
  </entry>

  <entry id="PSTRID_ROF">
    <type>integer</type>
    <value>1</value>
    <group>mach_pes_stride</group>
    <file>env_mach_pes.xml</file>
    <desc>stride of mpi tasks for rof comp - currently should always be set to 1</desc>
  </entry>

  <entry id="PSTRID_WAV">
    <type>integer</type>
    <valid_values>1</valid_values>
    <value>1</value>
    <group>mach_pes_stride</group>
    <file>env_mach_pes.xml</file>
    <desc>stride of mpi tasks for wav comp - currently should always be set to 1</desc>
  </entry>

  <entry id="TOTALPES">
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_last</group>
    <file>env_mach_pes.xml</file>
    <desc>total number of tasks and threads (setup automatically - DO NOT EDIT)</desc>
  </entry>

  <entry id="PES_LEVEL">
    <type>char</type>
    <value>UNSET</value>
    <group>mach_pes_last</group>
    <file>env_mach_pes.xml</file>
    <desc>pes level determined by automated initialization (DO NOT EDIT)</desc>
  </entry>

  <entry id="MAX_TASKS_PER_NODE"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_last</group>
    <file>env_mach_pes.xml</file>
    <desc>maximum number of tasks/ threads allowed per node </desc>
  </entry>

  <entry id="PES_PER_NODE"> 
    <type>integer</type>
    <value>0</value>
    <group>mach_pes_last</group>
    <file>env_mach_pes.xml</file>
    <desc>pes or cores per node for accounting purposes </desc>
  </entry>

  <!-- ===================================================================== -->
  <!-- definitions pio -->
  <!-- ===================================================================== -->

  <entry id="PIO_CONFIG_OPTS"> 
    <type>char</type>
    <value></value>
    <group>build_macros</group>
    <file>env_build.xml</file>
    <desc>PIO configure options, see PIO configure utility for details</desc>
  </entry>

  <entry id="PIO_ASYNC_INTERFACE">
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>TRUE implies perform asynchronous i/o</desc>
  </entry> 

  <entry id="PIO_STRIDE">
    <type>integer</type>
    <value>4</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>mpi task stride between io tasks</desc>
  </entry>

  <entry id="PIO_ROOT">
    <type>integer</type>
    <value>1</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio root processor</desc>
  </entry>

  <entry id="PIO_NUMTASKS">
    <type>integer</type>
    <value>-1</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio number of io tasks</desc>
  </entry>

  <entry id="PIO_TYPENAME">
    <type>char</type>
    <valid_values>netcdf,pnetcdf,netcdf4p,netcdf4c,default</valid_values>
    <value>netcdf</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio io type</desc>
  </entry> 

  <entry id="PIO_DEBUG_LEVEL">
    <type>integer</type>
    <value>0</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio debug level</desc>
  </entry>

  <entry id="PIO_BLOCKSIZE">
    <type>integer</type>
    <value>-1</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio blocksize</desc>
  </entry>

  <entry id="PIO_BUFFER_SIZE_LIMIT">
    <type>integer</type>
    <value>-1</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio buffer size limit</desc>
  </entry>

  <entry id="OCN_PIO_STRIDE">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio stride</desc>
  </entry>

  <entry id="OCN_PIO_ROOT">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio root processor</desc>
  </entry>

  <entry id="OCN_PIO_NUMTASKS">
    <type>integer</type>
    <value>-1</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio number of io tasks</desc>
  </entry>

  <entry id="OCN_PIO_TYPENAME">
    <type>char</type>
    <valid_values>nothing,netcdf,pnetcdf,netcdf4p,netcdf4c</valid_values>
    <value>nothing</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio io type</desc>
  </entry> 

  <entry id="LND_PIO_STRIDE">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio stride</desc>
  </entry>

  <entry id="LND_PIO_ROOT">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio root processor</desc>
  </entry>

  <entry id="LND_PIO_NUMTASKS">
    <type>integer</type>
    <value>-1</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio number of io tasks</desc>
  </entry>

  <entry id="LND_PIO_TYPENAME">
    <type>char</type>
    <valid_values>nothing,netcdf,pnetcdf,netcdf4p,netcdf4c</valid_values>
    <value>nothing</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio io type</desc>
  </entry> 

  <entry id="ROF_PIO_STRIDE">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio stride</desc>
  </entry>

  <entry id="ROF_PIO_ROOT">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio root processor</desc>
  </entry>

  <entry id="ROF_PIO_NUMTASKS">
    <type>integer</type>
    <value>-1</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio number of io tasks</desc>
  </entry>

  <entry id="ROF_PIO_TYPENAME">
    <type>char</type>
    <valid_values>nothing,netcdf,pnetcdf,netcdf4p,netcdf4c</valid_values>
    <value>nothing</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio io type</desc>
  </entry> 

  <entry id="ICE_PIO_STRIDE">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio stride</desc>
  </entry>

  <entry id="ICE_PIO_ROOT">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio root processor</desc>
  </entry>

  <entry id="ICE_PIO_NUMTASKS">
    <type>integer</type>
    <value>-1</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio number of io tasks</desc>
  </entry>

  <entry id="ICE_PIO_TYPENAME">
    <type>char</type>
    <valid_values>nothing,netcdf,pnetcdf,netcdf4p,netcdf4c</valid_values>
    <value>nothing</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio io type</desc>
  </entry> 

  <entry id="ATM_PIO_STRIDE">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio stride</desc>
  </entry>

  <entry id="ATM_PIO_ROOT">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio root processor</desc>
  </entry>

  <entry id="ATM_PIO_NUMTASKS">
    <type>integer</type>
    <value>-1</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio number of io tasks</desc>
  </entry>

  <entry id="ATM_PIO_TYPENAME">
    <type>char</type>
    <valid_values>nothing,netcdf,pnetcdf,netcdf4p,netcdf4c</valid_values>
    <value>nothing</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio io type</desc>
  </entry> 

  <entry id="CPL_PIO_STRIDE">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio stride</desc>
  </entry>

  <entry id="CPL_PIO_ROOT">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio root processor</desc>
  </entry>

  <entry id="CPL_PIO_NUMTASKS">
    <type>integer</type>
    <value>-1</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio number of io tasks</desc>
  </entry>

  <entry id="CPL_PIO_TYPENAME">
    <type>char</type>
    <valid_values>nothing,netcdf,pnetcdf,netcdf4p,netcdf4c</valid_values>
    <value>nothing</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio io type</desc>
  </entry> 

  <entry id="GLC_PIO_STRIDE">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio stride</desc>
  </entry>

  <entry id="GLC_PIO_ROOT">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio root processor</desc>
  </entry>

  <entry id="GLC_PIO_NUMTASKS">
    <type>integer</type>
    <value>-1</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio number of io tasks</desc>
  </entry>

  <entry id="GLC_PIO_TYPENAME">
    <type>char</type>
    <valid_values>nothing,netcdf,pnetcdf,netcdf4p,netcdf4c</valid_values>
    <value>nothing</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio io type</desc>
  </entry> 

  <entry id="WAV_PIO_STRIDE">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio stride</desc>
  </entry>

  <entry id="WAV_PIO_ROOT">
    <type>integer</type>
    <value>-99</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio root processor</desc>
  </entry>

  <entry id="WAV_PIO_NUMTASKS">
    <type>integer</type>
    <value>-1</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio number of io tasks</desc>
  </entry>

  <entry id="WAV_PIO_TYPENAME">
    <type>char</type>
    <valid_values>nothing,netcdf,pnetcdf,netcdf4p,netcdf4c</valid_values>
    <value>nothing</value>
    <group>run_pio</group>
    <file>env_run.xml</file>
    <desc>pio io type</desc>
  </entry>

  <!-- ===================================================================== -->
  <!-- definitions postproc -->
  <!-- diagnostics package toggles to include as part of in-line job run  -->
  <!-- ===================================================================== -->

  <entry id="AMWG_POSTPROC_DIAGS"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_dout</group>
    <file>env_run.xml</file>
    <desc>Call AMWG diagnostics plotting packages after successful completion of short term  archiver.
    If TRUE, this calls the AMWG diagnostics package parallel python wrapper
    script to generate climatological plots associated with the run job output.
    See the AMWG diagnostics documentation for more details.</desc>
  </entry> 

  <entry id="LMWG_POSTPROC_DIAGS"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_dout</group>
    <file>env_run.xml</file>
    <desc>Call LMWG diagnostics plotting packages after successful completion of short term  archiver.
    If TRUE, this calls the LMWG diagnostics package parallel python wrapper
    script to generate climatological plots associated with the run job output.
    See the LMWG diagnostics documentation for more details.</desc>
  </entry> 

  <entry id="OMWG_POSTPROC_DIAGS"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_dout</group>
    <file>env_run.xml</file>
    <desc>Call OMWG diagnostics plotting packages after successful completion of short term  archiver.
    If TRUE, this calls the OMWG diagnostics package parallel python wrapper
    script to generate climatological plots associated with the run job output.
    See the OMWG diagnostics documentation for more details.</desc>
  </entry> 

  <entry id="PCWG_POSTPROC_DIAGS"> 
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>run_dout</group>
    <file>env_run.xml</file>
    <desc>Call PCWG diagnostics plotting packages after successful completion of short term  archiver.
    If TRUE, this calls the PCWG diagnostics package parallel python wrapper
    script to generate climatological plots associated with the run job output.
    See the PCWG diagnostics documentation for more details.</desc>
  </entry> 

  <!-- ===================================================================== -->
  <!-- definitions testing -->
  <!-- ===================================================================== -->

  <entry id="NAME">
    <type>char</type>
    <value>UNSET</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>Test type name</desc>
  </entry>

  <entry id="DESC">
    <type>char</type>
    <value>UNSET</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>Test type descriptor</desc>
  </entry>

  <entry id="TESTCASE">
    <type>char</type>
    <value>UNSET</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>Testcase short name</desc>
  </entry>

  <entry id="CASEBASEID">
    <type>char</type>
    <value>UNSET</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>Case base ID</desc>
  </entry>

  <entry id="TEST_ARGV">
    <type>char</type>
    <value>UNSET</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>Arguments supplied to create_test</desc>
  </entry>

  <entry id="TEST_TESTID">
    <type>char</type>
    <value>UNSET</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>supplied or computed test id</desc>
  </entry>

  <entry id="GENERATE_BASELINE">
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>Whether to generate a baseline</desc>
  </entry>

  <entry id="COMPARE_BASELINE">
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>Whether to compare the baseline</desc>
  </entry>

  <entry id="BASEGEN_CASE">
    <type>char</type>
    <value>UNSET</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>The tagname we are comparing baselines against</desc>
  </entry>

  <entry id="BASECMP_CASE">
    <type>char</type>
    <value>UNSET</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>The tagname we are comparing baselines against</desc>
  </entry>

  <entry id="BASELINE_ROOT">
    <type>char</type>
    <value>/UNSET</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>The directory where baselines are stored</desc>
  </entry>

  <entry id="BASELINE_NAME_GEN">
    <type>char</type>
    <value>UNSET</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>The tagname we are generating baselines for</desc>
  </entry>

  <entry id="BASELINE_NAME_CMP">
    <type>char</type>
    <value>UNSET</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>The tagname we are comparing baselines against</desc>
  </entry>

  <entry id="CLEANUP">
    <type>logical</type>
    <valid_values>TRUE,FALSE</valid_values>
    <value>FALSE</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>Whether to clean the test after it is built/run</desc>
  </entry>

  <entry id="CCSM_BASELINE"> 
    <type>char</type>
    <value>/UNSET</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>standard baselines root directory for testing</desc>
  </entry> 

  <entry id="CCSM_CPRNC"> 
    <type>char</type>
    <value>/UNSET</value>
    <group>test</group>
    <file>env_test.xml</file>
    <desc>standard full pathname of the cprnc executable</desc>
  </entry> 

</definitions_variables> 
