#!/usr/bin/env python2

"""
script to create a case run script
"""

import sys, os, calendar, shutil

workdir = os.environ.get("PBS_O_WORKDIR")
if workdir is not None:
    os.chdir(workdir)

_CIMEROOT = os.environ.get("CIMEROOT")
if _CIMEROOT is None:
    raise exc_type("ERROR: must set CIMEROOT environment variable")

_LIBDIR = os.path.join(_CIMEROOT, "scripts", "Tools")
sys.path.append(_LIBDIR)

from standard_script_setup          import *
from CIME.XML.standard_module_setup import *
from CIME.case                      import Case
from CIME.utils                     import expect, get_model, run_cmd
from CIME.env_module                import EnvModule
from CIME.utils                     import expect, get_utc_timestamp
from CIME.check_lockedfiles         import check_lockedfiles
from CIME.preview_namelists         import preview_namelists

logger = logging.getLogger(__name__)

#---------------------------------
# Batch system directives 
#---------------------------------
{{ batchdirectives }}

#---------------------------------
# PE Layout Documentation:
#---------------------------------
{{ pedocumentation }}

###############################################################################
def parse_command_line(args):
###############################################################################

    parser = argparse.ArgumentParser()
    CIME.utils.setup_standard_logging_options(parser)
    args = parser.parse_args()
    CIME.utils.handle_standard_logging_options(args)

###############################################################################
def doPreRunChecks(case):
###############################################################################

    # Pre run initialization code..
    model          = CIME.utils.get_model()
    caseroot       = case.get_value("CASEROOT")
    cimeroot       = case.get_value("CIMEROOT")
    din_loc_root   = case.get_value("DIN_LOC_ROOT")
    compiler       = case.get_value("COMPILER")
    debug          = case.get_value("DEBUG")
    mach           = case.get_value("MACH")
    lbquery        = case.get_value("LBUQERY")
    batchsubmit    = case.get_value("BATCHSUBMIT")
    mpilib         = case.get_value("MPILIB")
    rundir         = case.get_value("RUNDIR")
    build_complete = case.get_value("BUILD_COMPLETE")

    # check for locked files.
    check_lockedfiles()
    logger.debug("check_lockedfiles OK")

    # load the module environment...
    env_module = EnvModule(mach, compiler, cimeroot, caseroot, mpilib, debug)
    env_module.load_env_for_case()

    # FIXME - handle mpilib differently than the original template.case.run
    # the old way was yellowstone specific

    expect (build_complete,
            "BUILD_COMPLETE is not true\nPlease rebuild the model interactively")
    logger.debug("build complete is %s " %build_complete)

    if batchsubmit is None or len(batchsubmit) == 0:
        os.environ["LBQUERY"] = "FALSE"
        os.environ["BATCHQUERY"] = "undefined"
    elif batchsubmit == 'UNSET':
        os.environ["LBQUERY"] = "FALSE"
        os.environ["BATCHQUERY"] = "undefined"
    else:
        os.environ["LBQUERY"] = "TRUE"
    
    # Create the timing directories, optionally cleaning them if needed.
    try:
        os.stat(rundir)
    except:
        os.mkdir(rundir)       

    if os.path.isdir(rundir + '/timing'):
        shutil.rmtree(rundir + '/timing')
    os.makedirs(rundir + '/timing/checkpoints')

    # Now set up the LID and sdate 
    os.environ["LID"] = get_utc_timestamp(timestamp_format="%y%m%d-%H%M%S") 

    localtime = get_utc_timestamp(timestamp_format="%Y-%m-%d %H:%M:%S")
    appendCaseStatus(caseroot, "Run started date %s \n" %localtime)

    preview_namelists()

    logger.info( "-------------------------------------------------------------------------")
    logger.info( " - To prestage required restarts, untar a restart.tar file into %s" %(rundir))
    logger.info( " - Case input data directory (DIN_LOC_ROOT) is %s " %(din_loc_root))
    logger.info( " - Checking for required input datasets in DIN_LOC_ROOT")
    logger.info( "-------------------------------------------------------------------------")

###############################################################################
def runModel(case):
###############################################################################

    # Run the model system
    rundir = case.get_value("RUNDIR")
    os.chdir(rundir)

    # system("sleep 10") #FIXME

    # Set OMP_NUM_THREADS
    num_threads = {{ thread_count }}
    os.environ["OMP_NUM_THREADS"] = str(num_threads)

    # Run the model

    localtime = get_utc_timestamp(timestamp_format="%Y-%m-%d %H:%M:%S")
    logger.info("%s MODEL EXECUTION BEGINS HERE" %localtime)

    {{ mpirun }}
    cmd = case.get_resolved_value(cmd)
    logger.debug("run command is %s " %cmd)
    #run_cmd(cmd) #DEBUG

    localtime = get_utc_timestamp(timestamp_format="%Y-%m-%d %H:%M:%S")
    logger.info( "%s MODEL EXECUTION HAS FINISHED" %localtime)

###############################################################################
def postRun(case):
###############################################################################

    # Post-processing

    caseroot     = case.get_value("CASEROOT")
    rundir       = case.get_value("RUNDIR")
    logdir       = case.get_value("LOGDIR")
    model        = case.get_value("MODEL")
    check_timing = case.get_value("CHECK_TIMING")
    save_timing  = case.get_value("SAVE_TIMING")

    lid = os.environ["LID"]

    localtime = get_utc_timestamp(timestamp_format="%Y-%m-%d %H:%M:%S")

    # find the last model.log and cpl.log
    model_logfile = os.path.join(rundir,model + ".log." + lid)
    cpl_logfile   = os.path.join(rundir,"cpl" + ".log." + lid)

    if os.path.isfile(model_logfile):
        msg = "Model did not complete, no model log file %s " %(model_logfile)
        appendCaseStatus(caseroot,msg)
        expect(False, msg)

    if not os.path.isfile(cpl_logfile):
        msg = "Model did not complete, no cpl log file %s" %(cpl_logfile) 
        appendCaseStatus(caseroot, msg)
        expect(False, msg)

    if os.stat(model_logfile).st_size == 0:
        msg = " Run FAILED localtime " %(localtime)
        appendCaseStatus(caseroot, msg)
    else:
        if 'SUCCESSFUL TERMINATION' in open(cpl_logfile).read():
            msg = "run SUCCESSFUL %s" %(localtime)
            appendCaseStatus(caseroot, msg )
        else:
            msg = "Model did not complete - see %s " %(cpl_logfile)
            appendCaseStatus(caseroot, msg)
            expect (False, msg)

    # Copy log files back to caseroot
    if logdir is not None and len(logdir) > 0:
        if not os.path.isdir(logdir):
            os.makedirs(logdir)
        logger.debug("lid %s" %(lid))
        comps = ("atm", "glc", "ice", "lnd", "ocn", "rof", "wav", "cpl", "cesm", "esp") 
        for comp in comps:
	    disposeLog(case, comp ,lid, logdir)

    # Run the getTiming script if desired
    if check_timing:
        timingDir = os.path.join(caseroot,"/timing")
        if not os.path.isdir(timingDir):
            os.makedirs(timingDir)
        logger.info("running timing script..")

        cmd = "%s -lid %s " %(os.path.join(caseroot,"Tools/getTiming"), lid)
        run_cmd(cmd)

        logger.info( "gzipping timing stats.." )
        timingfile = model + "_timing_stats." + lid
        cmd = "gzip %s " %(os.path,join(caseroot,timingfile))
        run_cmd(cmd)

    # Save the timing files if desired
    if save_timing:
        shutil.move(os.path.join(rundir,"timing"), 
                    os.path.join(rundir,"timing."+lid))


###############################################################################
def appendCaseStatus(caseroot, msg):
###############################################################################

    with open(os.path.join(caseroot,"CaseStatus"), "a") as fd:
        fd.write(msg)


###############################################################################
def disposeLog(case, component, lid, logdir):
###############################################################################

    caseroot = case.get_value("CASEROOT")
    rundir =  case.get_value("RUNDIR")

    logfile = os.path.join(rundir, component + '.log.' + lid)
    if os.path.isfile(logfile):
        cmd = "gzip " + logfile
        run_cmd(cmd)
	logfile = logfile + ".gz"
	if os.path.isfile(logfile):
            caselogfile = os.path.join(caseroot, os.path.basename(logfile))
            shutil.copy(logfile, caselogfile)


###############################################################################
def _main_func():
###############################################################################

    # Set up the run, run the model, do the postrun steps

    parse_command_line(sys.argv)

    case = Case()

    run_with_submit = case.get_value("RUN_WITH_SUBMIT")
    # expect (run_with_submit,
    #         "You are not calling the run script via the submit script. "
    #         "As a result, short-term archiving will not be called automatically."
    #         "Please submit your run by calling ./case.submit")
    case.set_value("RUN_WITH_SUBMIT","TRUE") #??? need to call case.flush

    casename = case.get_value("CASE")
    caseroot = case.get_value("CASEROOT")
    rundir   = case.get_value("RUNDIR")
    logdir   = case.get_value("LOGDIR")
    data_assimilation        = case.get_value("DATA_ASSIMILATION")
    data_assimilation_cycles = case.get_value("DATA_ASSIMILATION_CYCLES")
    data_assimilation_script = case.get_value("DATA_ASSIMILATION_SCRIPT")

    for cycle in range(0,data_assimilation_cycles):
        doPreRunChecks(case)
        runModel(case)
        postRun(case)
    #     DoDataAssimilation(rundir, caseroot, 
    #                        data_assimilation, data_assimilation_script,
    #                        lid, logdir)
    # resubmitCheck()

###############################################################################

if __name__ == "__main__":
    _main_func()
